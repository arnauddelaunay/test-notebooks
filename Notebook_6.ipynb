{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"center\" width=\"300\" src=\"static/images/logo-training.png\" />\n",
    "\n",
    "<h1  style=\"text-align:center\"> Notebook #6 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>KNN</h1>\n",
    "<h2>K-nearnest-neighbors</h2>\n",
    "<p> Some models are very interesting to work with because they show how a simple idea can lead to a powerful model.\n",
    "We will here show the K-neighbors model. The idea is to find the K (an integer) nearest neighbors of a point (i.e. a specific sample) to predict its own label</p>\n",
    "<img src=\"https://i0.wp.com/adataanalyst.com/wp-content/uploads/2016/07/kNN-1.png?w=267\" width=\"600\"/>\n",
    "\n",
    "<p>\n",
    "    Also, note that :\n",
    "    <ul>\n",
    "        <li>The position of a point is based on the value of its features</li>\n",
    "        <li>Given K a number of neighbors, the final prediciton can vary (on the image above, two different prediciton can be made depeding on the value of K, 3 or 5 </li>\n",
    "        <li>This model has no parameters, it will only compute the distances between the samples to save time during the inference</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16, 4\n",
    "import matplotlib.pyplot as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    The cells below will recreate the new features introduced in the notebook n° 4.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/customerLifetimeValue.csv\", sep=\";\")\n",
    "#We take the columns we need for our models and get the underlying matrix\n",
    "X_numeric = dataset[[\"price_first_item_purchased\", \"pages_visited\"]]\n",
    "#We also take a categorical variable\n",
    "X_categorical = dataset[\"Country\"]\n",
    "#and we create a new feature\n",
    "X_numeric = X_numeric.assign(priceByVisited_pages = X_numeric[\"price_first_item_purchased\"]/X_numeric[\"pages_visited\"])\n",
    "#We binarize the target, all value greater than a given revenue will become positive (1), other negative(0)\n",
    "y = dataset[\"revenue\"].apply(lambda x: 0 if x <= 175 else 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "#We fill missing categorical value with \"unknown\"\n",
    "#like linear model, KNN needs binarized categories\n",
    "X_categorical.fillna(\"unknown\", inplace=True)\n",
    "my_binarizer = LabelBinarizer()\n",
    "binarized_categories = my_binarizer.fit_transform(X_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We join data, but with this model we don't need to drop the first column\n",
    "#then we concatenate the matrix with the numerical variables\n",
    "X = np.hstack([X_numeric.values, binarized_categories])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    As you can see, the syntax is always pretty much the same : feature creation, splitting test and train, fitting the model...\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We create test and train datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1337)\n",
    "#first we try with five neighbors\n",
    "model = KNeighborsClassifier(n_neighbors=4)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "train_score = roc_auc_score(y_train, model.predict(X_train))\n",
    "test_score = roc_auc_score(y_test, model.predict(X_test))\n",
    "print(\"train score : %f, test score : %f\"%(train_score, test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model works well but it require the number of neighbors to select. To define the best number of neighbors, we will test different K values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kValues = []\n",
    "testValues = []\n",
    "for n in range(2, 20) :\n",
    "    model = KNeighborsClassifier(n_neighbors=n)\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted_test = model.predict(X_test)\n",
    "    predicted_train = model.predict(X_train)\n",
    "    score_test = roc_auc_score(y_test, predicted_test)\n",
    "    score_train = roc_auc_score(y_train, predicted_train)\n",
    "    testValues.append(score_test)\n",
    "    kValues.append(n)\n",
    "    #print(\"K : %d, train score : %f, test score : %f\"%(n, score_train, score_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.plot(kValues, testValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In the cell above, we've tested different values of K. This method is called Grid-Search : different hyper-parameters (parmeters that are not learnt but choosen by the data scientist) are tested to find the optimal value.</p>\n",
    "<p>\n",
    "    The image below shows how the classification boundary changes depending on K :\n",
    "    <img src=\"https://elvinouyang.github.io/assets/images/Introduction%20to%20Machine%20Learning%20with%20Python%20-%20Chapter%202%20-%20Datasets%20and%20kNN_files/Introduction%20to%20Machine%20Learning%20with%20Python%20-%20Chapter%202%20-%20Datasets%20and%20kNN_31_1.png\" />\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1 style=\"text-align:center; color:orange\">YOUR TURN</h1>\n",
    "<hr>\n",
    "<b>A] try to predict the country of a buyer given the features of your choice !</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
